{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T07:01:29.614729Z",
     "start_time": "2022-03-28T07:01:28.648226Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T07:01:29.724883Z",
     "start_time": "2022-03-28T07:01:29.615729Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "\n",
    "africa_train_paths = glob(\"./open/train/africa/*.wav\")\n",
    "australia_train_paths = glob(\"./open/train/australia/*.wav\")\n",
    "canada_train_paths = glob(\"./open/train/canada/*.wav\")\n",
    "england_train_paths = glob(\"./open/train/england/*.wav\")\n",
    "hongkong_train_paths = glob(\"./open/train/hongkong/*.wav\")\n",
    "us_train_paths = glob(\"./open/train/us/*.wav\")\n",
    "\n",
    "path_list = [africa_train_paths, australia_train_paths, canada_train_paths,\n",
    "             england_train_paths, hongkong_train_paths, us_train_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T07:01:29.804778Z",
     "start_time": "2022-03-28T07:01:29.725733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./open/test\\1.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./open/test\\10.wav</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./open/test\\100.wav</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./open/test\\1000.wav</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./open/test\\1001.wav</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path    id\n",
       "0     ./open/test\\1.wav     1\n",
       "1    ./open/test\\10.wav    10\n",
       "2   ./open/test\\100.wav   100\n",
       "3  ./open/test\\1000.wav  1000\n",
       "4  ./open/test\\1001.wav  1001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob로 test data의 path를 불러올때 순서대로 로드되지 않을 경우를 주의해야 합니다.\n",
    "# test_ 데이터 프레임을 만들어서 나중에 sample_submission과 id를 기준으로 merge시킬 준비를 합니다.\n",
    "\n",
    "def get_id(data):\n",
    "    return np.int(data.split(\"\\\\\")[1].split(\".\")[0])\n",
    "\n",
    "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
    "test_[\"path\"] = glob(\"./open/test/*.wav\")\n",
    "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
    "\n",
    "test_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline 코드에서는 librosa 라이브러리를 사용하여 wav파일을 전처리 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T07:01:29.820786Z",
     "start_time": "2022-03-28T07:01:29.805779Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        # sr = 16000이 의미하는 것은 1초당 16000개의 데이터를 샘플링 한다는 것입니다.\n",
    "        data, sr = librosa.load(path, sr = 16000)\n",
    "        result.append(data)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경해 주세요 ex) np.array(data, dtype = np.float32)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:25:49.870698Z",
     "start_time": "2022-03-28T07:01:29.821786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [06:40<00:00,  6.24it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.40it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.40it/s]\n",
      "100%|██████████| 10000/10000 [26:31<00:00,  6.28it/s] \n",
      "100%|██████████| 1020/1020 [02:51<00:00,  5.93it/s]\n",
      "100%|██████████| 10000/10000 [26:31<00:00,  6.28it/s] \n",
      "100%|██████████| 6100/6100 [16:17<00:00,  6.24it/s] \n"
     ]
    }
   ],
   "source": [
    "# train 데이터를 로드하기 위해서는 많은 시간이 소모 됩니다.\n",
    "# 따라서 추출된 정보를 npy파일로 저장하여 필요 할 때마다 불러올 수 있게 준비합니다.\n",
    "\n",
    "os.mkdir(\"./npy_data\")\n",
    "\n",
    "africa_train_data = load_data(africa_train_paths)\n",
    "np.save(\"./npy_data/africa_npy\", africa_train_data)\n",
    "\n",
    "australia_train_data = load_data(australia_train_paths)\n",
    "np.save(\"./npy_data/australia_npy\", australia_train_data)\n",
    "\n",
    "canada_train_data = load_data(canada_train_paths)\n",
    "np.save(\"./npy_data/canada_npy\", canada_train_data)\n",
    "\n",
    "england_train_data = load_data(england_train_paths)\n",
    "np.save(\"./npy_data/england_npy\", england_train_data)\n",
    "\n",
    "hongkong_train_data = load_data(hongkong_train_paths)\n",
    "np.save(\"./npy_data/hongkong_npy\", hongkong_train_data)\n",
    "\n",
    "us_train_data = load_data(us_train_paths)\n",
    "np.save(\"./npy_data/us_npy\", us_train_data)\n",
    "\n",
    "test_data = load_data(test_[\"path\"])\n",
    "np.save(\"./npy_data/test_npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:26:02.495731Z",
     "start_time": "2022-03-28T08:25:49.872699Z"
    }
   },
   "outputs": [],
   "source": [
    "# npy파일로 저장된 데이터를 불러옵니다.\n",
    "africa_train_data = np.load(\"./npy_data/africa_npy.npy\", allow_pickle = True)\n",
    "australia_train_data = np.load(\"./npy_data/australia_npy.npy\", allow_pickle = True)\n",
    "canada_train_data = np.load(\"./npy_data/canada_npy.npy\", allow_pickle = True)\n",
    "england_train_data = np.load(\"./npy_data/england_npy.npy\", allow_pickle = True)\n",
    "hongkong_train_data = np.load(\"./npy_data/hongkong_npy.npy\", allow_pickle = True)\n",
    "us_train_data = np.load(\"./npy_data/us_npy.npy\", allow_pickle = True)\n",
    "\n",
    "test_data = np.load(\"./npy_data/test_npy.npy\", allow_pickle = True)\n",
    "\n",
    "train_data_list = [africa_train_data, australia_train_data, canada_train_data, england_train_data, hongkong_train_data, us_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:26:02.511744Z",
     "start_time": "2022-03-28T08:26:02.497580Z"
    }
   },
   "outputs": [],
   "source": [
    "# 이번 대회에서 음성은 각각 다른 길이를 갖고 있습니다.\n",
    "# baseline 코드에서는 음성 중 길이가 가장 작은 길이의 데이터를 기준으로 데이터를 잘라서 사용합니다.\n",
    "\n",
    "def get_mini(data):\n",
    "\n",
    "    mini = 9999999\n",
    "    for i in data:\n",
    "        if len(i) < mini:\n",
    "            mini = len(i)\n",
    "\n",
    "    return mini\n",
    "\n",
    "#음성들의 길이를 맞춰줍니다.\n",
    "\n",
    "def set_length(data, d_mini):\n",
    "\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "#feature를 생성합니다.\n",
    "\n",
    "def get_feature(data, sr = 16000, n_fft = 256, win_length = 200, hop_length = 160, n_mels = 64):\n",
    "    mel = []\n",
    "    for i in data:\n",
    "        # win_length 는 음성을 작은 조각으로 자를때 작은 조각의 크기입니다.\n",
    "        # hop_length 는 음성을 작은 조각으로 자를때 자르는 간격을 의미합니다.\n",
    "        # n_mels 는 적용할 mel filter의 개수입니다.\n",
    "        mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "        mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref = np.max)\n",
    "\n",
    "    mel_mean = mel.mean()\n",
    "    mel_std = mel.std()\n",
    "    mel = (mel - mel_mean) / mel_std\n",
    "\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:01.424892Z",
     "start_time": "2022-03-28T08:26:02.513581Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = np.concatenate(train_data_list, axis= 0)\n",
    "test_x = np.array(test_data)\n",
    "\n",
    "# 음성의 길이 중 가장 작은 길이를 구합니다.\n",
    "\n",
    "train_mini = get_mini(train_x)\n",
    "test_mini = get_mini(test_x)\n",
    "\n",
    "mini = np.min([train_mini, test_mini])\n",
    "\n",
    "# data의 길이를 가장 작은 길이에 맞춰 잘라줍니다.\n",
    "\n",
    "train_x = set_length(train_x, mini)\n",
    "test_x = set_length(test_x, mini)\n",
    "\n",
    "# librosa를 이용해 feature를 추출합니다.\n",
    "\n",
    "train_x = get_feature(data = train_x)\n",
    "test_x = get_feature(data = test_x)\n",
    "\n",
    "train_x = train_x.reshape(-1, train_x.shape[1], train_x.shape[2], 1)\n",
    "test_x = test_x.reshape(-1, test_x.shape[1], test_x.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:01.440892Z",
     "start_time": "2022-03-28T08:29:01.427897Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data의 label을 생성해 줍니다.\n",
    "\n",
    "train_y = np.concatenate((np.zeros(len(africa_train_data), dtype = np.int),\n",
    "                        np.ones(len(australia_train_data), dtype = np.int),\n",
    "                         np.ones(len(canada_train_data), dtype = np.int) * 2,\n",
    "                         np.ones(len(england_train_data), dtype = np.int) * 3,\n",
    "                         np.ones(len(hongkong_train_data), dtype = np.int) * 4,\n",
    "                         np.ones(len(us_train_data), dtype = np.int) * 5), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:01.455960Z",
     "start_time": "2022-03-28T08:29:01.442893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25520, 64, 501, 1), (25520,), (6100, 64, 501, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분석 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 분석 모델은 월간데이콘_6 음성 중첩 데이터 분류 AI 경진대회 3위를 달성하신 Jamm님의 코드를 바탕으로 만들어졌습니다.  \n",
    " https://www.dacon.io/competitions/official/235616/codeshare/1571?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:06.562287Z",
     "start_time": "2022-03-28T08:29:01.457963Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
    "                                     Dropout, Dense, AveragePooling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:06.578261Z",
     "start_time": "2022-03-28T08:29:06.563296Z"
    }
   },
   "outputs": [],
   "source": [
    "def block(input_, units = 32, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:29:06.593296Z",
     "start_time": "2022-03-28T08:29:06.579262Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    dropout_rate = 0.3\n",
    "    \n",
    "    in_ = Input(shape = (train_x.shape[1:]))\n",
    "    \n",
    "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
    "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
    "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
    "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    x = Flatten()(block_05)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units = 6, activation = 'softmax')(x)\n",
    "    model = Model(in_, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:52:15.969027Z",
     "start_time": "2022-03-28T08:29:06.594280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "638/638 [==============================] - 49s 53ms/step - loss: 1.5677 - acc: 0.3899 - val_loss: 1.3226 - val_acc: 0.4179\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.3166 - acc: 0.4352 - val_loss: 1.3649 - val_acc: 0.4212\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2573 - acc: 0.4823 - val_loss: 1.3508 - val_acc: 0.4316\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1964 - acc: 0.5271 - val_loss: 1.8047 - val_acc: 0.4189\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1559 - acc: 0.5479 - val_loss: 1.4988 - val_acc: 0.4136\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1050 - acc: 0.5743 - val_loss: 1.4972 - val_acc: 0.4561\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1052 - acc: 0.5774 - val_loss: 1.2944 - val_acc: 0.4683\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.0061 - acc: 0.6253 - val_loss: 1.2731 - val_acc: 0.5374\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 35s 52ms/step - loss: 1.5304 - acc: 0.4027 - val_loss: 1.8207 - val_acc: 0.3009\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.3134 - acc: 0.4563 - val_loss: 1.4099 - val_acc: 0.4449\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2378 - acc: 0.5027 - val_loss: 1.4503 - val_acc: 0.4863\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1774 - acc: 0.5477 - val_loss: 140.4247 - val_acc: 0.0486\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2814 - acc: 0.4663 - val_loss: 1.3488 - val_acc: 0.4643\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2688 - acc: 0.4745 - val_loss: 4.3191 - val_acc: 0.1571\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2398 - acc: 0.4858 - val_loss: 1.5054 - val_acc: 0.3870\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2254 - acc: 0.4995 - val_loss: 1.2898 - val_acc: 0.4518\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 35s 53ms/step - loss: 1.5578 - acc: 0.3987 - val_loss: 1.3421 - val_acc: 0.4641\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2844 - acc: 0.4571 - val_loss: 1.3559 - val_acc: 0.4291\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2169 - acc: 0.5119 - val_loss: 1.4775 - val_acc: 0.4314\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1488 - acc: 0.5554 - val_loss: 1.1558 - val_acc: 0.5760\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.0701 - acc: 0.6041 - val_loss: 3.1629 - val_acc: 0.2551\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.0294 - acc: 0.6249 - val_loss: 1.4132 - val_acc: 0.5069\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.0088 - acc: 0.6285 - val_loss: 1.1763 - val_acc: 0.5762\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 0.9700 - acc: 0.6505 - val_loss: 8.2543 - val_acc: 0.1001\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 35s 53ms/step - loss: 1.5805 - acc: 0.3997 - val_loss: 1.4634 - val_acc: 0.3879\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.3028 - acc: 0.4760 - val_loss: 1.6780 - val_acc: 0.2941\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2068 - acc: 0.5252 - val_loss: 1.4680 - val_acc: 0.4937\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1116 - acc: 0.5812 - val_loss: 1.6060 - val_acc: 0.5072\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.0549 - acc: 0.6058 - val_loss: 1.1395 - val_acc: 0.5562\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 0.9863 - acc: 0.6323 - val_loss: 1.0177 - val_acc: 0.6223\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 0.9452 - acc: 0.6512 - val_loss: 1.1272 - val_acc: 0.6021s: 0.9487 -  - ETA: 2s - \n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 0.8936 - acc: 0.6714 - val_loss: 1.0470 - val_acc: 0.6105\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 35s 53ms/step - loss: 1.5729 - acc: 0.3940 - val_loss: 1.3287 - val_acc: 0.4344\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.3056 - acc: 0.4662 - val_loss: 1.6162 - val_acc: 0.2859\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.2403 - acc: 0.5018 - val_loss: 1.4595 - val_acc: 0.4101\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1828 - acc: 0.5332 - val_loss: 1.2297 - val_acc: 0.5098\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1185 - acc: 0.5729 - val_loss: 1.2640 - val_acc: 0.4796\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1438 - acc: 0.5574 - val_loss: 1.4624 - val_acc: 0.4792\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1655 - acc: 0.5365 - val_loss: 1.2282 - val_acc: 0.4973\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 33s 52ms/step - loss: 1.1931 - acc: 0.5364 - val_loss: 1.2093 - val_acc: 0.5339\n",
      "*******************************************************************\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "pred = []\n",
    "pred_ = []\n",
    "\n",
    "for train_idx, val_idx in split.split(train_x, train_y):\n",
    "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "    model = build_fn()\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.002),\n",
    "                 loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics = ['acc'])\n",
    "\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = 8)\n",
    "    print(\"*******************************************************************\")\n",
    "    pred.append(model.predict(test_x))\n",
    "    pred_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "    print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:52:16.001040Z",
     "start_time": "2022-03-28T08:52:15.970033Z"
    }
   },
   "outputs": [],
   "source": [
    "def cov_type(data):\n",
    "    return np.int(data)\n",
    "\n",
    "# 처음에 살펴본 것처럼 glob로 test data의 path는 sample_submission의 id와 같이 1,2,3,4,5.....으로 정렬 되어있지 않습니다.\n",
    "# 만들어둔 test_ 데이터프레임을 이용하여 sample_submission과 predict값의 id를 맞춰줍니다.\n",
    "\n",
    "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n",
    "result[\"id\"] = result[\"id\"].apply(lambda x : cov_type(x))\n",
    "\n",
    "result = pd.merge(sample_submission[\"id\"], result)\n",
    "result.columns = sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:52:16.017090Z",
     "start_time": "2022-03-28T08:52:16.002040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.081180</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.227791</td>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.196294</td>\n",
       "      <td>0.310562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.140754</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.047008</td>\n",
       "      <td>0.395727</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.388569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.289965</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.420874</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.235376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.200857</td>\n",
       "      <td>0.045339</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.495348</td>\n",
       "      <td>0.039959</td>\n",
       "      <td>0.211113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>0.183983</td>\n",
       "      <td>0.038093</td>\n",
       "      <td>0.642877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.281649</td>\n",
       "      <td>0.182847</td>\n",
       "      <td>0.196283</td>\n",
       "      <td>0.306426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0.066110</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.256483</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.618554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0.153915</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.304693</td>\n",
       "      <td>0.205671</td>\n",
       "      <td>0.297192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0.273270</td>\n",
       "      <td>0.022367</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.216333</td>\n",
       "      <td>0.116568</td>\n",
       "      <td>0.362065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0.110495</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.267223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    africa  australia    canada   england  hongkong        us\n",
       "0        1  0.081180   0.011587  0.227791  0.172586  0.196294  0.310562\n",
       "1        2  0.140754   0.015116  0.047008  0.395727  0.012825  0.388569\n",
       "2        3  0.289965   0.024995  0.004752  0.420874  0.024038  0.235376\n",
       "3        4  0.200857   0.045339  0.007385  0.495348  0.039959  0.211113\n",
       "4        5  0.104367   0.012193  0.018487  0.183983  0.038093  0.642877\n",
       "...    ...       ...        ...       ...       ...       ...       ...\n",
       "6095  6096  0.022506   0.010289  0.281649  0.182847  0.196283  0.306426\n",
       "6096  6097  0.066110   0.018404  0.006888  0.256483  0.033560  0.618554\n",
       "6097  6098  0.153915   0.032215  0.006315  0.304693  0.205671  0.297192\n",
       "6098  6099  0.273270   0.022367  0.009398  0.216333  0.116568  0.362065\n",
       "6099  6100  0.110495   0.024157  0.008715  0.452261  0.137149  0.267223\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T08:52:16.048109Z",
     "start_time": "2022-03-28T08:52:16.018094Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"DACON.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline은 참가자의 제출을 최우선 목표로 하고 있습니다.  \n",
    "창의적인 전처리 방법을 적용하고 훌륭한 분석 모델을 개발해 주세요  \n",
    "  \n",
    "감사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
